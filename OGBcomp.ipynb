{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.2.2, while the latest version is 1.2.3.\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import GraphPropPredDataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ogbcomp_helper as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = {}\n",
    "all_ap = {}\n",
    "all_rocs = {}\n",
    "train_label_props = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if quick_test:\n",
    "    n_estimators = 100\n",
    "    max_tasks = 3\n",
    "    nreps = 1\n",
    "else:\n",
    "    n_estimators = 1000\n",
    "    max_tasks = None\n",
    "    nreps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 79/5000 [00:00<00:06, 781.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot checking order between mapping file and graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1020.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 437929/437929 [00:59<00:00, 7387.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catenating results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled label balance:\n",
      "0.0    109506\n",
      "1.0     11256\n",
      "Name: PCBA-1030, dtype: int64\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:22<00:45, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCBA-1030, rep 0, AP (val, test): 0.459, 0.415\n",
      "\tROC (val, test): 0.804, 0.776\n",
      "Sampled label balance:\n",
      "0.0    50000\n",
      "1.0      396\n",
      "Name: PCBA-1379, dtype: int64\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:27<00:17, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCBA-1379, rep 0, AP (val, test): 0.123, 0.136\n",
      "\tROC (val, test): 0.885, 0.856\n",
      "Sampled label balance:\n",
      "0.0    50000\n",
      "1.0      142\n",
      "Name: PCBA-1452, dtype: int64\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCBA-1452, rep 0, AP (val, test): 0.041, 0.235\n",
      "\tROC (val, test): 0.841, 0.845\n",
      "Reading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 130/5000 [00:00<00:03, 1292.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot checking order between mapping file and graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1067.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 41127/41127 [00:05<00:00, 7287.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catenating results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled label balance:\n",
      "0    31669\n",
      "1     1232\n",
      "Name: HIV_active, dtype: int64\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV_active, rep 0, AP (val, test): 0.386, 0.408\n",
      "\tROC (val, test): 0.833, 0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for rep in range(nreps):\n",
    "    for ds in [\"ogbg-molpcba\", \"ogbg-molhiv\"]:\n",
    "        # Read in dataset\n",
    "        print(\"Reading dataset\")\n",
    "        dataset = GraphPropPredDataset(name=ds)\n",
    "        \n",
    "        # By default, the line above will save data to the path below\n",
    "        df_smi = pd.read_csv(f\"dataset/{ds}/mapping/mol.csv.gz\".replace(\"-\", \"_\"))\n",
    "        smiles = df_smi[\"smiles\"]\n",
    "        outcomes = df_smi.set_index(\"smiles\").drop([\"mol_id\"], axis=1)\n",
    "        \n",
    "        # Make sure smiles strings and graphs are in the same order so splits are valid\n",
    "        helper.spotcheck_order(smiles, dataset)\n",
    "\n",
    "        # Generate features\n",
    "        print(\"Extracting features...\")\n",
    "        X = helper.parallel_apply(smiles, func=helper.getmorganfingerprint2)\n",
    "\n",
    "        # Split into train/val/test\n",
    "        split_idx = dataset.get_idx_split()\n",
    "        train_idx, val_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "        X_train, X_val, X_test = X.iloc[train_idx], X.iloc[val_idx], X.iloc[test_idx]\n",
    "\n",
    "        for oo in tqdm(outcomes.columns[:max_tasks]):\n",
    "            # Get probabilities\n",
    "            val_key = ds, oo, rep, \"val\"\n",
    "            test_key = ds, oo, rep, \"test\"\n",
    "            \n",
    "            # If re-running, skip finished runs\n",
    "            if val_key in all_probs:\n",
    "                print(\"Skipping\", val_key[:-1])\n",
    "                continue\n",
    "    \n",
    "            # Split outcome in to train/val/test\n",
    "            Y = outcomes[oo]\n",
    "            y_train, y_val, y_test = Y.loc[X_train.index], Y.loc[X_val.index], Y.loc[X_test.index]\n",
    "            \n",
    "            # Skip outcomes with no positive training examples\n",
    "            if y_train.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            # Remove missing labels in validation\n",
    "            y_val, y_test = y_val.dropna(), y_test.dropna()\n",
    "            X_v, X_t = X_val.loc[y_val.index], X_test.loc[y_test.index]\n",
    "            \n",
    "            # Remove missing values in the training labels, and downsample imbalance to cut runtime\n",
    "            y_tr = helper.process_y(y_train)\n",
    "            train_label_props[ds, oo, rep] = y_tr.mean()\n",
    "            print(f\"Sampled label balance:\\n{y_tr.value_counts()}\")\n",
    "            \n",
    "            # Fit model\n",
    "            print(\"Fitting model...\")\n",
    "            rf = RandomForestClassifier(min_samples_leaf=2, n_estimators=n_estimators, n_jobs=-1)\n",
    "            rf.fit(X_train.loc[y_tr.index], y_tr)\n",
    "\n",
    "            # Calculate probabilities\n",
    "            all_probs[val_key] = pd.Series(rf.predict_proba(X_v)[:, 1], index=X_v.index)\n",
    "            all_probs[test_key] = pd.Series(rf.predict_proba(X_t)[:, 1], index=X_t.index)\n",
    "\n",
    "            if y_val.sum() > 0:\n",
    "                all_ap[val_key] = average_precision_score(y_val, all_probs[val_key])\n",
    "                all_rocs[val_key] = roc_auc_score(y_val, all_probs[val_key])\n",
    "            \n",
    "            if y_test.sum() > 0:\n",
    "                all_ap[test_key] = average_precision_score(y_test, all_probs[test_key])\n",
    "                all_rocs[test_key] = roc_auc_score(y_test, all_probs[test_key])\n",
    "\n",
    "            print(f'{oo}, rep {rep}, AP (val, test): {all_ap.get(val_key, np.nan):.3f}, {all_ap.get(test_key, np.nan):.3f}')\n",
    "            print(f'\\tROC (val, test): {all_rocs.get(val_key, np.nan):.3f}, {all_rocs.get(test_key, np.nan):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"ogb_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ogb_results/results.pkl\", \"wb\") as fout:\n",
    "    all_results = {\n",
    "        \"probs\": all_probs,\n",
    "        \"AP\": all_ap,\n",
    "        \"ROCs\": all_rocs,\n",
    "        \"Label_props\": train_label_props\n",
    "    }\n",
    "    pickle.dump(all_results, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read results from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ogb_results/results.pkl\", \"rb\") as fin:\n",
    "    all_results = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = all_results[\"probs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ogbg-molpcba ===\n",
      "--> val\n",
      "            ap\n",
      "mean  0.222616\n",
      "std   0.000232\n",
      "\n",
      "--> test\n",
      "            ap\n",
      "mean  0.205363\n",
      "std   0.000363\n",
      "\n",
      "\n",
      "=== ogbg-molhiv ===\n",
      "--> val\n",
      "        rocauc\n",
      "mean  0.842090\n",
      "std   0.003541\n",
      "\n",
      "--> test\n",
      "        rocauc\n",
      "mean  0.806663\n",
      "std   0.000983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in [\"ogbg-molpcba\", \"ogbg-molhiv\"]:\n",
    "    outcomes = (\n",
    "        pd.read_csv(f\"dataset/{task}/mapping/mol.csv.gz\".replace(\"-\", \"_\"))\n",
    "        .set_index(\"smiles\")\n",
    "        .drop([\"mol_id\"], axis=1)\n",
    "    )\n",
    "    \n",
    "    evaluator = Evaluator(name=task)\n",
    "    \n",
    "    print(f\"\\n=== {task} ===\")\n",
    "    for dset in [\"val\", \"test\"]:\n",
    "        scores = []\n",
    "        probs = helper.probs_dict2df(all_probs, task=task, dset=dset)\n",
    "        for rep in range(4):\n",
    "            tt = probs[rep]\n",
    "            input_dict = {\"y_true\": outcomes.loc[tt.index, tt.columns].values, \n",
    "                          \"y_pred\": tt.values}\n",
    "            scores.append(evaluator.eval(input_dict))\n",
    "        print(f\"--> {dset}\")\n",
    "        print(pd.DataFrame(scores).agg([np.mean, np.std]))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogb",
   "language": "python",
   "name": "ogb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
